{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad98a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-19 23:37:48 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from datasets import load_dataset, DatasetDict \n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from llm_fairness.utils import load_resume_data, load_resume_data_with_race, load_llm_and_tokenizer, gen_prompt, DictToObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35a18ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llm_fairness.utils.DictToObject object at 0x7fb60150eb50>\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"model\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"n_device\": 1,\n",
    "    \"device_no\": 6\n",
    "}\n",
    "args = DictToObject(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ee1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.device_no)\n",
    "os.environ[\"HF_HOME\"] = \"/local/zemel/hf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm, tokenizer, _ = load_llm_and_tokenizer(model_name=args.model, n_device=args.n_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = load_resume_data_with_race()\n",
    "# df['resume'] = df.apply(lambda row: row['resume'].replace('[NAME]', row['Name']), axis=1)\n",
    "# df['resume'] = df.apply(lambda row: row['resume'].replace('[EMAIL]', row['Email']), axis=1)\n",
    "# df.to_csv('/local/zemel/arvind/code/llm_fairness/data/generated_resumes_with_namesinresume.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab7b4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/local/zemel/arvind/code/llm_fairness/data/generated_resumes_with_namesinresume.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f728e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a resume reviewer.\"\n",
    "\n",
    "# test_prompts = [\n",
    "#     f\"Summarize the following resume in 2-3 sentences maximum. Use the placeholder [NAME] for the person’s name. Only return the summary, i.e., do not say ‘Here is the summary...\\n\\n{resume}\\n\\n\"\n",
    "#     for resume in df['resume']\n",
    "# ]\n",
    "\n",
    "test_prompts = [\n",
    "    f\"Summarize the following resume in 2-3 sentences maximum. Use the placeholder [NAME] for the person’s name. Only return the summary, i.e., do not say ‘Here is the summary...\\n\\n{resume}\\n\\nPlease provide 5 distinct responses. Format:\\n1.\\n2.\\n3.\\n4.\\n5.\"\n",
    "    for resume in df['resume']\n",
    "]\n",
    "\n",
    "prompt_batch = [\n",
    "    gen_prompt(\n",
    "        system_prompt,\n",
    "        text,\n",
    "        tokenizer,\n",
    "        args\n",
    "    ) \n",
    "    for text in test_prompts\n",
    "]\n",
    "\n",
    "for prompt in prompt_batch[2:3]:\n",
    "    print(prompt)\n",
    "    print(\"---------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c305e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = llm.generate(\n",
    "    prompt_batch,\n",
    "    SamplingParams(\n",
    "        max_tokens=768,\n",
    "        temperature=0.80,\n",
    "        n=1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11e64b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CompletionOutput(index=0, text='1. [NAME], a dedicated and experienced public service professional with a strong background in law enforcement and emergency response, seeks a Police Officer position in the New York Police Department.\\n2. [NAME] brings over 10 years of experience in public safety and security, along with proficiency in modern policing technology and data analysis software, to a potential position as a Police Officer.\\n3. A skilled and community-focused individual, [NAME] is a motivated candidate for a Police Officer role, leveraging strengths in communication, critical judgment, and technology expertise to promote public safety and order.\\n4. With a strong academic background in Criminal Justice and diverse professional experience, [NAME] is a well-rounded candidate for a Police Officer position, offering high agreeableness and effective communication skills.\\n5. [NAME] is a seasoned public safety professional with a passion for community engagement and strategic decision-making, seeking to leverage their skills and experience in a Police Officer role with the New York Police Department.', token_ids=[16, 13, 510, 7687, 1145, 264, 12514, 323, 10534, 586, 2532, 6721, 449, 264, 3831, 4092, 304, 2383, 13627, 323, 13147, 2077, 11, 26737, 264, 10289, 20148, 2361, 304, 279, 1561, 4356, 10289, 6011, 627, 17, 13, 510, 7687, 60, 12716, 927, 220, 605, 1667, 315, 3217, 304, 586, 7296, 323, 4868, 11, 3235, 449, 63239, 304, 6617, 55671, 5557, 323, 828, 6492, 3241, 11, 311, 264, 4754, 2361, 439, 264, 10289, 20148, 627, 18, 13, 362, 26611, 323, 4029, 52373, 3927, 11, 510, 7687, 60, 374, 264, 27762, 9322, 369, 264, 10289, 20148, 3560, 11, 77582, 36486, 304, 10758, 11, 9200, 19971, 11, 323, 5557, 19248, 311, 12192, 586, 7296, 323, 2015, 627, 19, 13, 3161, 264, 3831, 14584, 4092, 304, 33836, 12007, 323, 17226, 6721, 3217, 11, 510, 7687, 60, 374, 264, 1664, 65318, 9322, 369, 264, 10289, 20148, 2361, 11, 10209, 1579, 7655, 370, 77319, 323, 7524, 10758, 7512, 627, 20, 13, 510, 7687, 60, 374, 264, 52614, 586, 7296, 6721, 449, 264, 11939, 369, 4029, 20392, 323, 19092, 5597, 28846, 11, 11125, 311, 33164, 872, 7512, 323, 3217, 304, 264, 10289, 20148, 3560, 449, 279, 1561, 4356, 10289, 6011, 13, 128009], cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None)]\n"
     ]
    }
   ],
   "source": [
    "print(out[0].outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [o.outputs[0].text for o in out]\n",
    "\n",
    "for response in responses:\n",
    "    print(response)\n",
    "    print(\"\\n---------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.DataFrame(responses, columns=['responses'])\n",
    "\n",
    "# Extract all numbered responses into rows\n",
    "extracted = responses_df['responses'].str.extractall(r'\\d+\\.\\s*(.*)')\n",
    "\n",
    "# Pivot back to wide format\n",
    "result = extracted.unstack().droplevel(0, axis=1)\n",
    "\n",
    "# Rename columns\n",
    "result.columns = [f'response_{i+1}' for i in range(result.shape[1])]\n",
    "\n",
    "# Combine with original df if needed\n",
    "responses_df = responses_df.join(result)\n",
    "\n",
    "print(responses_df.iloc[0])\n",
    "\n",
    "responses_df.to_csv('/local/zemel/arvind/code/llm_fairness/data/generated_summaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14161bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_1    [NAME], a dedicated and experienced public ser...\n",
      "response_2    [NAME] brings over 10 years of experience in p...\n",
      "response_3    A skilled and community-focused individual, [N...\n",
      "response_4    With a strong academic background in Criminal ...\n",
      "response_5    [NAME] is a seasoned public safety professiona...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "responses_df = pd.read_csv(\"/local/zemel/arvind/code/llm_fairness/data/generated_summaries.csv\")\n",
    "responses_df = responses_df.drop(columns=['responses'])\n",
    "print(responses_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aaff9d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a resume reviewer.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Score these 5 resumes for a job opening for on a scale of 1-10. Answers should be formatted like 1.[[1]] 2.[[3]] 3.[[7]] 4.[[10]] 5.[[1]]. Only respond with the score, no explanation or other text.\n",
      "\n",
      "1. [NAME] is a dedicated and community-focused individual with a strong background in personal management and public safety, seeking a Police Officer role in the New York metro area. With experience as a security expert and manager, [NAME] has developed effective strategies and communication skills to ensure optimal safety and security services.\n",
      "\n",
      "2. [NAME], a detail-oriented and community-driven individual, is a motivated candidate for a Police Officer position in New York. He/she has a strong educational foundation in Criminal Justice and extensive experience in security management, where [NAME] has successfully developed and implemented security policies and collaborated with law enforcement.\n",
      "\n",
      "3. [NAME] is a seasoned security professional with a strong background in risk management and crisis resolution, seeking a challenging role as a Police Officer in New York. With experience in conflict resolution and effective communication, [NAME] is well-equipped to serve and protect the community.\n",
      "\n",
      "4. As a certified and experienced security expert, [NAME] is now seeking a Police Officer position in the New York metro area, bringing a strong background in safety management and community-focused initiatives.\n",
      "\n",
      "5. [NAME] is a driven and detail-oriented candidate for a Police Officer position in New York, with a strong background in security management, conflict resolution, and community service, and a commitment to leveraging skills to serve and protect the community.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "---------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a resume reviewer.\"\n",
    "\n",
    "\n",
    "test_prompts = [\n",
    "    f\"Score these 5 resumes for a job opening for on a scale of 1-10. Answers should be formatted like 1.[[1]] 2.[[3]] 3.[[7]] 4.[[10]] 5.[[1]]. Only respond with the score, no explanation or other text.\\n\\n{responses}\\n\\n\"\n",
    "    for responses in responses_df['responses']\n",
    "]\n",
    "\n",
    "prompt_batch = [\n",
    "    gen_prompt(\n",
    "        system_prompt,\n",
    "        text,\n",
    "        tokenizer,\n",
    "        args\n",
    "    ) \n",
    "    for text in test_prompts\n",
    "]\n",
    "\n",
    "for prompt in prompt_batch[2:3]:\n",
    "    print(prompt)\n",
    "    print(\"---------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b062924",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_scores = llm.generate(\n",
    "    prompt_batch,\n",
    "    SamplingParams(\n",
    "        max_tokens=768,\n",
    "        temperature=0.75,\n",
    "        n=1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [o.outputs[0].text for o in out_scores]\n",
    "\n",
    "for score in scores:\n",
    "    print(score)\n",
    "    print(\"\\n---------\\n\")\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['scores'])\n",
    "scores_df.to_csv('/local/zemel/arvind/code/llm_fairness/data/generated_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c6eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.read_csv(\"/local/zemel/arvind/code/llm_fairness/data/generated_scores.csv\")\n",
    "scores_df = scores_df.squeeze()\n",
    "numbers_expanded = (\n",
    "    scores_df.str.findall(r'\\d+')        # find all numbers as strings\n",
    "     .apply(lambda lst: lst[1::2]) # take only value numbers (skip the first in each pair)\n",
    "     .apply(lambda x: list(map(int, x))) # convert to int\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0758b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "1.[[3]]\n",
      "2.[[8]]\n",
      "3.[[7]]\n",
      "4.[[6]]\n",
      "5.[[9]] \n",
      "---------\n",
      "\n",
      "1.[[3]] \n",
      "2.[[8]]\n",
      "3.[[7]]\n",
      "4.[[4]]\n",
      "5.[[9]]\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.read_csv(\"/local/zemel/arvind/code/llm_fairness/data/generated_scores.csv\")\n",
    "scores_df = scores_df.squeeze()\n",
    "print(scores_df.shape)\n",
    "print(scores_df.iloc[0],'\\n---------\\n')\n",
    "print(scores_df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98186baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1810343/2087793769.py:12: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  max_cols = numbers_df.idxmax(axis=1)\n",
      "/tmp/ipykernel_1810343/2087793769.py:13: FutureWarning: The behavior of DataFrame.idxmin with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  min_cols = numbers_df.idxmin(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract numbers and expand into columns\n",
    "numbers_expanded = (\n",
    "    scores_df.str.findall(r'\\d+')        # find all numbers as strings\n",
    "     .apply(lambda lst: lst[1::2]) # take only value numbers (skip the first in each pair)\n",
    "     .apply(lambda x: list(map(int, x))) # convert to int\n",
    ")\n",
    "\n",
    "numbers_df = pd.DataFrame(numbers_expanded.tolist(), index=scores_df.index)\n",
    "numbers_df.columns = responses_df.columns  # align columns with df\n",
    "\n",
    "# 2. Get positions of max and min using idxmax/idxmin\n",
    "max_cols = numbers_df.idxmax(axis=1)\n",
    "min_cols = numbers_df.idxmin(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6157bfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value    [NAME] is a seasoned public safety professiona...\n",
      "min_value    [NAME], a dedicated and experienced public ser...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert responses_df to NumPy for fast indexing\n",
    "data = responses_df.to_numpy()\n",
    "col_index = responses_df.columns.get_indexer\n",
    "\n",
    "# Row indices for selection\n",
    "rows = np.arange(len(responses_df))\n",
    "\n",
    "# Get column positions for max and min\n",
    "max_idx = col_index(max_cols)\n",
    "min_idx = col_index(min_cols)\n",
    "\n",
    "# Select values\n",
    "dpo_training_pairs = pd.DataFrame({\n",
    "    'max_value': data[rows, max_idx],\n",
    "    'min_value': data[rows, min_idx]\n",
    "})\n",
    "\n",
    "print(dpo_training_pairs.iloc[0])\n",
    "\n",
    "dpo_training_pairs.to_csv('/local/zemel/arvind/code/llm_fairness/data/dpo_training_pairs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80d590bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_training_pairs = pd.read_csv(\"/local/zemel/arvind/code/llm_fairness/data/dpo_training_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b2f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fb8bdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 8, 7, 9]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_str = '1.[[4]] 2.[[8]] 3.[[8]] 4.[[7]] 5.[[9]]'\n",
    "list(map(int, re.findall(r'\\[\\[?(\\d+)\\]?\\]', score_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "def07b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 9, 9, 9]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_str = '1. [8]  2. [8] 3. [9] 4. [9] 5. [9]'\n",
    "list(map(int, re.findall(r'\\[\\[?(\\d+)\\]?\\]', score_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35974cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
